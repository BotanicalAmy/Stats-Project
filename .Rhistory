price_model <- glm(factor(Status) ~ AvgPrice, family = binomial(link = "logit"), data = hotel_bookings)
#summary(price_model)
leadtime_model <- glm(factor(Status) ~ LeadTime, family = binomial(link = "logit"), data = hotel_bookings)
#summary(leadtime_model)
staylength_model <- glm(factor(Status) ~ StayLength, family = binomial(link = "logit"), data = hotel_bookings)
#summary(staylength_model)
groupsize_model <- glm(factor(Status) ~ GroupSize, family = binomial(link = "logit"), data = hotel_bookings)
#summary(groupsize_model)
#ASSESS
#converts status to binary where Canceled = 1 and Not_Canceled = 0, checking for linearity
hotel_bookings$Status_binary <- ifelse(hotel_bookings$Status == "Canceled", 1, 0)
emplogitplot1(Status_binary ~ LeadTime, data = hotel_bookings, ngroups = "all")
plot(leadtime_model, which = 1)
#USE
# summary(leadtime_model)
# Parameters from your logistic regression model
intercept <- 1.8046260
lead_time_coef <- -0.0117484
# Function to calculate probability of cancellation
cancellation_probability <- function(lead_time) {
logit <- intercept + (lead_time_coef * lead_time)
probability <- 1 / (1 + exp(-logit))
return(probability)
}
# Function to calculate odds of cancellation
cancellation_odds <- function(lead_time) {
prob <- cancellation_probability(lead_time)
odds <- prob / (1 - prob)
return(odds)
}
# Create a sequence of lead times from 0 to 365 days
lead_times <- seq(0, 365, by = 1)
# Calculate probabilities and odds for each lead time
probabilities <- sapply(lead_times, cancellation_probability)
odds <- sapply(lead_times, cancellation_odds)
# Create a data frame for plotting
plot_data <- data.frame(
LeadTime = lead_times,
Probability = probabilities,
Odds = odds
)
# Create visualization
# Set up a 2x1 plotting layout
par(mfrow = c(2, 1), mar = c(4, 4, 2, 2))
# Plot 1: Probability vs Lead Time
plot(plot_data$LeadTime, plot_data$Probability,
type = "l", col = "royalblue", lwd = 2,
xlab = "Lead Time (days)", ylab = "Probability of Cancellation",
main = "Probability of Cancellation vs Lead Time",
ylim = c(0, 1))
grid()
# Add reference points
reference_points <- c(0, 30, 60, 90, 180, 365)
reference_probs <- sapply(reference_points, cancellation_probability)
points(reference_points, reference_probs, pch = 19, col = "#FF6B6B")
# Add labels for probability reference points
text(reference_points, reference_probs,
labels = paste0(round(reference_probs*100, 1), "%"),
pos = 3, col = "gray11")
# Plot 2: Odds vs Lead Time
plot(plot_data$LeadTime, plot_data$Odds,
type = "l", col = "midnightblue", lwd = 2,
xlab = "Lead Time (days)", ylab = "Odds of Cancellation",
main = "Odds of Cancellation vs Lead Time",
ylim = c(0, 6))
grid()
# Add reference points for odds
reference_odds <- sapply(reference_points, cancellation_odds)
points(reference_points, reference_odds, pch = 19, col = "#FF6B6B")
# Add labels for odds reference points
text(reference_points, reference_odds,
labels = paste0(round(reference_odds, 2)),
pos = 3, col = "gray11")
# Reset plotting parameters
par(mfrow = c(1, 1))
# Additional information: Compare probability and odds changes
# reference_table <- data.frame(
#   LeadTime = reference_points,
#   Probability = round(reference_probs, 4),
#   ProbabilityPercentage = paste0(round(reference_probs*100, 1), "%"),
#   Odds = round(reference_odds, 4)
# )
# Print reference table
# print(reference_table)
# Calculate and display odds ratios for different intervals
# base_odds <- cancellation_odds(0)
# odds_ratios <- sapply(reference_points[-1], function(lt) {
#   cancellation_odds(lt) / base_odds
# })
#
# cat("\nPercentage change in odds from Lead Time = 0:\n")
# for (i in 1:length(odds_ratios)) {
#   pct_change <- (odds_ratios[i] - 1) * 100
#   cat(sprintf("Lead Time = %d days: %.1f%% change in odds\n",
#               reference_points[i+1], pct_change))
# }
# Calculate and display odds ratio for one-day change
# one_day_odds_ratio <- exp(lead_time_coef)
# cat(sprintf("\nOdds ratio for one-day increase in lead time: %.4f\n", one_day_odds_ratio))
# cat(sprintf("This corresponds to a %.2f%% decrease in odds per day\n",
#             (1 - one_day_odds_ratio) * 100))
modr <- glm(factor(Status) ~ HasRequests, family = binomial(link = "logit"), data = hotel_bookings)
# summary(modr)
plot(modr, which = 1)
#confidence interval for HasRequests
#confint.default(modr)
mod1 <- glm(factor(Status) ~ RoomType, family = binomial(link = "logit"), data = hotel_bookings)
# summary(mod1)
# plot(mod1, which = 1)
mod2 <- glm(factor(Status) ~ Parking, family = binomial(link = "logit"), data = hotel_bookings)
# summary(mod2)
# plot(mod2, which = 1)
mod3 <- glm(factor(Status) ~ Market, family = binomial(link = "logit"), data = hotel_bookings)
# summary(mod3)
# plot(mod3, which = 1)
mod4 <- glm(factor(Status) ~ Meal, family = binomial(link = "logit"), data = hotel_bookings)
# summary(mod4)
# plot(mod4, which = 1)
# mod5 <- glm(factor(Status) ~ Month, family = binomial(link = "logit"), data = hotel_bookings)
# summary(mod5)
#plot(mod5, which = 1)
# included again in the appendix, left here for ease of reference or modification
new_model <- glm(factor(Status) ~ LeadTime + factor(Market) + HasRequests + factor(Month) + AvgPrice + StayLength, family = binomial(link = "logit"), data=hotel_bookings)
anova_table <- Anova(new_model, test = "LR")
# print(anova_table)
# Get the AIC
# AIC(new_model)
#ASSESS
# Create an empirical logit plot for the entire model
plot_model_fit <- function(model, bins = 10) {
# Get predicted probabilities from the model
pred_probs <- predict(model, type = "response")
# Get actual responses (as 0/1)
actual <- as.numeric(model$model[[1]]) - 1
# Create bins based on predicted probabilities
breaks <- quantile(pred_probs, probs = seq(0, 1, length.out = bins + 1))
bin_groups <- cut(pred_probs, breaks = breaks, include.lowest = TRUE)
# Calculate empirical logit for each bin
bin_data <- data.frame(
bin = bin_groups,
pred = pred_probs,
actual = actual
)
# Calculate average predicted probability and observed proportion for each bin
bin_summary <- aggregate(cbind(pred, actual) ~ bin, data = bin_data,
FUN = function(x) c(mean(x)))
# Calculate empirical logit
bin_summary$logit_pred <- log(bin_summary$pred / (1 - bin_summary$pred))
bin_summary$logit_actual <- log((bin_summary$actual + 0.5/nrow(bin_summary)) /
(1 - bin_summary$actual + 0.5/nrow(bin_summary)))
# Count observations per bin
bin_counts <- table(bin_groups)
bin_summary$count <- as.vector(bin_counts)
# Create plot
plot(bin_summary$logit_pred, bin_summary$logit_actual,
xlab = "Predicted logit", ylab = "Observed logit",
main = "Empirical Logit Plot for Model Fit",
pch = 19, cex = sqrt(bin_summary$count / max(bin_summary$count)) * 2)
# Add reference line (y = x)
abline(0, 1, col = "red", lty = 2)
# Add regression line
abline(lm(logit_actual ~ logit_pred, data = bin_summary,
weights = count), col = "blue")
# Add legend
legend("topleft", legend = c("Perfect fit", "Actual fit"),
col = c("red", "blue"), lty = c(2, 1))
return(bin_summary)
}
# Create the empirical logit plot for the model
model_fit <- plot_model_fit(new_model, bins = 10)
# Print the bin summary data
#print(model_fit)
# Other diagnostic plots for the model
plot(new_model, which = c(1, 2))  # Residuals vs Fitted and Normal Q-Q plot
#cross validation, note- this validation not included in the description (text still notes my original k fold analysis)
# Set seed for reproducibility
set.seed(123)
# Create a random split (80% training, 20% test)
train_indices <- sample(1:nrow(hotel_bookings), size = 0.8 * nrow(hotel_bookings))
train_data <- hotel_bookings[train_indices, ]
test_data <- hotel_bookings[-train_indices, ]
# Build the model on training data
train_model <- glm(factor(Status) ~ LeadTime + factor(Market) + HasRequests +
factor(Month) + AvgPrice + StayLength,
family = binomial(link = "logit"),
data = train_data)
# get predictions for both training and test data
train_predictions <- predict(train_model, newdata = train_data, type = "response")
test_predictions <- predict(train_model, newdata = test_data, type = "response")
# Convert actual values to binary for comparison
train_actual <- as.numeric(factor(train_data$Status)) - 1
test_actual <- as.numeric(factor(test_data$Status)) - 1
# Calculate correlation in training data
# train_correlation <- cor(train_predictions, train_actual)
# print(paste("Training correlation:", round(train_correlation, 4)))
# Calculate correlation in test data (this is the CVC)
# test_correlation <- cor(test_predictions, test_actual)
# print(paste("Cross-validation correlation (CVC):", round(test_correlation, 4)))
# Calculate shrinkage
# shrinkage <- train_correlation - test_correlation
# print(paste("Shrinkage:", round(shrinkage, 4)))
# print(paste("Shrinkage percentage:", round(shrinkage/train_correlation * 100, 2), "%"))
#gets the confidence interval, which does not include 0 therefore valid
# confint.default(leadtime_model)
#gets the CI on the odds ratio scale, for every 1 unit increase in LeadTime, the odds of cancellation
#(vs. non-cancellation) multiply by 0.9880 to 0.9881 w/95% confidence
# exp(confint.default(leadtime_model))
#confidence interval for HasRequests
# confint.default(modr)
# side-by-side bar chart of canceled bookings by market type for 2017-2018
# Filter for canceled bookings in 2017 and 2018 only
canceled_bookings <- hotel_bookings[hotel_bookings$Status == "Canceled" &
(hotel_bookings$Year == 2017 |
hotel_bookings$Year == 2018), ]
# Create a binary market type variable (Online vs Non-Online)
canceled_bookings$MarketType <- ifelse(canceled_bookings$Market == "Online",
"Online", "Non-Online")
# Create a contingency table of counts
cancellation_counts <- table(canceled_bookings$Year, canceled_bookings$MarketType)
# Convert to data frame for ggplot
cancellation_df <- as.data.frame(cancellation_counts)
colnames(cancellation_df) <- c("Year", "MarketType", "Count")
# Convert Year to factor for proper ordering
cancellation_df$Year <- as.factor(cancellation_df$Year)
# Create the side-by-side (unstacked) bar chart
ggplot(cancellation_df, aes(x = Year, y = Count, fill = MarketType)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7) +
scale_fill_manual(values = c("Online" = "darkblue", "Non-Online" = "azure4")) +
labs(title = "Canceled Bookings by Market Type (2017-2018)",
subtitle = "Side-by-side comparison of Online vs Non-Online Markets",
x = "Year",
y = "Number of Cancellations",
fill = "Market Type") +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
plot.subtitle = element_text(size = 12, hjust = 0.5),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
legend.position = "bottom",
legend.title = element_text(size = 11),
legend.text = element_text(size = 10),
panel.grid = element_blank()  # Keep the gridlines removed
) +
# Add data labels on top of each bar
geom_text(aes(label = Count), position = position_dodge(width = 0.7),
vjust = -0.5, size = 3.5) +
# Set y-axis to start at 0
scale_y_continuous(expand = expansion(mult = c(0, 0.1)))
# function to generate proportion tables
create_prop_table <- function(data, group_var) {
group_var <- enquo(group_var)
data %>%
group_by(!!group_var, Status) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(!!group_var) %>%
mutate(proportion = count / sum(count))
}
# using the function with each variable
room_type_table <- create_prop_table(hotel_bookings, RoomType)
meal_table <- create_prop_table(hotel_bookings, Meal)
market_table <- create_prop_table(hotel_bookings, Market)
parking_table <- create_prop_table(hotel_bookings, Parking)
month_table <- create_prop_table(hotel_bookings, Month)
requests_table <- create_prop_table(hotel_bookings, HasRequests)
children_table <- create_prop_table(hotel_bookings, HasChildren)
online_table <- create_prop_table(hotel_bookings, Online)
# using the function to create a nicely formatted kable table with rounded proportions
print_pretty_kable <- function(table_data, title) {
table_data <- table_data %>%
mutate(proportion = round(proportion, 3))
kable(table_data, caption = title) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
full_width = FALSE) %>%
column_spec(1, bold = TRUE) %>%
row_spec(0, bold = TRUE)
}
#printed tables are separated with lines of code to prevent awkward cut offs
# Print each table with nice formatting
print_pretty_kable(room_type_table, "Room Type")
print_pretty_kable(meal_table, "Meal Option")
print_pretty_kable(market_table, "Market")
print_pretty_kable(parking_table, "Parking")
print_pretty_kable(month_table, "Month")
print_pretty_kable(requests_table, "Special Requests")
# Print each table with nice formatting
print_pretty_kable(children_table, "Has Children")
print_pretty_kable(online_table, "Online Booking")
# quantitative code
price_model <- glm(factor(Status) ~ AvgPrice, family = binomial(link = "logit"), data = hotel_bookings)
summary(price_model)
leadtime_model <- glm(factor(Status) ~ LeadTime, family = binomial(link = "logit"), data = hotel_bookings)
summary(leadtime_model)
staylength_model <- glm(factor(Status) ~ StayLength, family = binomial(link = "logit"), data = hotel_bookings)
summary(staylength_model)
groupsize_model <- glm(factor(Status) ~ GroupSize, family = binomial(link = "logit"), data = hotel_bookings)
summary(groupsize_model)
# categorical code
modr <- glm(factor(Status) ~ Requests, family = binomial(link = "logit"), data = hotel_bookings)
summary(modr)
mod1 <- glm(factor(Status) ~ RoomType, family = binomial(link = "logit"), data = hotel_bookings)
summary(mod1)
mod2 <- glm(factor(Status) ~ Parking, family = binomial(link = "logit"), data = hotel_bookings)
summary(mod2)
mod3 <- glm(factor(Status) ~ Market, family = binomial(link = "logit"), data = hotel_bookings)
summary(mod3)
mod4 <- glm(factor(Status) ~ Meal, family = binomial(link = "logit"), data = hotel_bookings)
summary(mod4)
mod5 <- glm(factor(Status) ~ Month, family = binomial(link = "logit"), data = hotel_bookings)
summary(mod5)
#full model code
full_model <- glm(factor(Status) ~ factor(Meal) + factor(Parking) + factor(RoomType) + LeadTime + factor(Market) + AvgPrice + HasRequests + factor(Month) + StayLength + GroupSize, family = binomial(link = "logit"), data=hotel_bookings)
none <- glm(factor(Status) ~ 1 , family = binomial(link = "logit"), data=hotel_bookings)
step(none,scope=list(upper= full_model), direction = "forward")
anova_table <- Anova(full_model, test = "LR")
print(anova_table)
#final model code
new_model <- glm(factor(Status) ~ LeadTime + factor(Market) + HasRequests + factor(Month) + AvgPrice + StayLength, family = binomial(link = "logit"), data=hotel_bookings)
anova_table <- Anova(new_model, test = "LR")
print(anova_table)
# Get the AIC
AIC(new_model)
#Cross validation
# Set seed for reproducibility
set.seed(123)
# Define number of folds
k <- 10
# Create folds
folds <- sample(1:k, nrow(hotel_bookings), replace = TRUE)
# Initialize performance metrics
cv_metrics <- data.frame(
fold = 1:k,
accuracy = numeric(k),
sensitivity = numeric(k),
specificity = numeric(k),
auc = numeric(k)
)
# Perform k-fold cross-validation
for (i in 1:k) {
# Split data into training and test sets
train_data <- hotel_bookings[folds != i, ]
test_data <- hotel_bookings[folds == i, ]
# Fit model on training data
cv_model <- glm(factor(Status) ~ LeadTime + factor(Market) + HasRequests +
factor(Month) + AvgPrice + StayLength,
family = binomial(link = "logit"),
data = train_data)
# Make predictions on test data
predictions <- predict(cv_model, newdata = test_data, type = "response")
predicted_class <- ifelse(predictions > 0.5, 1, 0)
actual_class <- as.numeric(factor(test_data$Status)) - 1
# Create confusion matrix
conf_matrix <- table(Predicted = predicted_class, Actual = actual_class)
# Calculate performance metrics
if (dim(conf_matrix)[1] == 2 && dim(conf_matrix)[2] == 2) {
# When both classes are present in the fold
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[, 2])
specificity <- conf_matrix[1, 1] / sum(conf_matrix[, 1])
# Calculate AUC
library(pROC)
roc_obj <- roc(actual_class, predictions)
auc_value <- auc(roc_obj)
} else {
# Handle edge case when a fold might be missing a class
accuracy <- sum(predicted_class == actual_class) / length(actual_class)
sensitivity <- NA
specificity <- NA
auc_value <- NA
}
# Store metrics for this fold
cv_metrics$accuracy[i] <- accuracy
cv_metrics$sensitivity[i] <- sensitivity
cv_metrics$specificity[i] <- specificity
cv_metrics$auc[i] <- auc_value
}
# Calculate average performance across folds
cv_summary <- colMeans(cv_metrics[, -1], na.rm = TRUE)
cv_sd <- apply(cv_metrics[, -1], 2, sd, na.rm = TRUE)
# Print results
print("Cross-validation results:")
print(cv_metrics)
print("Average performance:")
print(cv_summary)
print("Standard deviation of performance:")
#data summary of folds
print(cv_sd)
# quantitative EDA
# Compare means of each quantitative variable between canceled and not canceled groups
group_comparison <- hotel_bookings %>%
group_by(Status) %>%
summarize(
Mean_LeadTime = mean(LeadTime, na.rm = TRUE),
Mean_AvgPrice = mean(AvgPrice, na.rm = TRUE),
Mean_GroupSize = mean(GroupSize, na.rm = TRUE),
Mean_StayLength = mean(StayLength, na.rm = TRUE)
)
# Round numeric columns to 3 decimal places
group_comparison_formatted <- group_comparison %>%
mutate(across(where(is.numeric), ~round(., 3)))
# Create pretty kable table
kable(group_comparison_formatted, caption = "Quantitative Explanatory Variables") %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
full_width = FALSE) %>%
column_spec(1, bold = TRUE) %>%
row_spec(0, bold = TRUE)
hotel_long <- hotel_bookings %>%
select(Status, LeadTime, AvgPrice, GroupSize, StayLength) %>%
pivot_longer(cols = c(LeadTime, AvgPrice, GroupSize, StayLength),
names_to = "Variable",
values_to = "Value")
# faceted boxplots for quantitative variables
ggplot(hotel_long, aes(x = Status, y = Value, fill = Status)) +
geom_boxplot() +
facet_wrap(~ Variable, scales = "free_y") +
scale_fill_manual(values = c("Canceled" = "#FF6B6B", "Not_Canceled" = "#4ECDC4")) +
labs(title = "Comparison of quantitative variables by cancellation status") +
theme_minimal()
# side-by-side bar chart of canceled bookings by market type for 2017-2018
# Filter for canceled bookings in 2017 and 2018 only
canceled_bookings <- hotel_bookings[hotel_bookings$Status == "Canceled" &
(hotel_bookings$Year == 2017 |
hotel_bookings$Year == 2018), ]
# Create a binary market type variable (Online vs Non-Online)
canceled_bookings$MarketType <- ifelse(canceled_bookings$Market == "Online",
"Online", "Non-Online")
# Create a contingency table of counts
cancellation_counts <- table(canceled_bookings$Year, canceled_bookings$MarketType)
# Convert to data frame for ggplot
cancellation_df <- as.data.frame(cancellation_counts)
colnames(cancellation_df) <- c("Year", "MarketType", "Count")
# Convert Year to factor for proper ordering
cancellation_df$Year <- as.factor(cancellation_df$Year)
# Create the side-by-side (unstacked) bar chart
ggplot(cancellation_df, aes(x = Year, y = Count, fill = MarketType)) +
geom_bar(stat = "identity", position = "dodge", width = 0.7) +
scale_fill_manual(values = c("Online" = "darkblue", "Non-Online" = "azure4")) +
labs(title = "Canceled Bookings by Market Type (2017-2018)",
subtitle = "Side-by-side comparison of Online vs Non-Online Markets",
x = "Year",
y = "Number of Cancellations",
fill = "Market Type") +
theme_minimal() +
theme(
plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
plot.subtitle = element_text(size = 12, hjust = 0.5),
axis.title = element_text(size = 12),
axis.text = element_text(size = 10),
legend.position = "bottom",
legend.title = element_text(size = 11),
legend.text = element_text(size = 10),
panel.grid = element_blank()  # Keep the gridlines removed
) +
# Add data labels on top of each bar
geom_text(aes(label = Count), position = position_dodge(width = 0.7),
vjust = -0.5, size = 3.5) +
# Set y-axis to start at 0
scale_y_continuous(expand = expansion(mult = c(0, 0.1)))
# function to generate proportion tables
create_prop_table <- function(data, group_var) {
group_var <- enquo(group_var)
data %>%
group_by(!!group_var, Status) %>%
summarise(count = n(), .groups = "drop") %>%
group_by(!!group_var) %>%
mutate(proportion = count / sum(count))
}
# using the function with each variable
room_type_table <- create_prop_table(hotel_bookings, RoomType)
meal_table <- create_prop_table(hotel_bookings, Meal)
market_table <- create_prop_table(hotel_bookings, Market)
parking_table <- create_prop_table(hotel_bookings, Parking)
month_table <- create_prop_table(hotel_bookings, Month)
requests_table <- create_prop_table(hotel_bookings, HasRequests)
children_table <- create_prop_table(hotel_bookings, HasChildren)
online_table <- create_prop_table(hotel_bookings, Online)
# using the function to create a nicely formatted kable table with rounded proportions
print_pretty_kable <- function(table_data, title) {
table_data <- table_data %>%
mutate(proportion = round(proportion, 3))
kable(table_data, caption = title) %>%
kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
full_width = FALSE) %>%
column_spec(1, bold = TRUE) %>%
row_spec(0, bold = TRUE)
}
#printed tables are separated with lines of code to prevent awkward cut offs
# Print each table with nice formatting
print_pretty_kable(room_type_table, "Room Type")
print_pretty_kable(meal_table, "Meal Option")
# Print each table with nice formatting
print_pretty_kable(market_table, "Market")
print_pretty_kable(parking_table, "Parking")
print_pretty_kable(month_table, "Month")
print_pretty_kable(requests_table, "Special Requests")
# Print each table with nice formatting
print_pretty_kable(children_table, "Has Children")
print_pretty_kable(online_table, "Online Booking")
# Print each table with nice formatting
print_pretty_kable(market_table, "Market")
print_pretty_kable(parking_table, "Parking")
print_pretty_kable(month_table, "Month")
print_pretty_kable(requests_table, "Special Requests")
# Print each table with nice formatting
print_pretty_kable(market_table, "Market")
print_pretty_kable(parking_table, "Parking")
# Print each table with nice formatting
print_pretty_kable(month_table, "Month")
print_pretty_kable(requests_table, "Special Requests")
# Print each table with nice formatting
print_pretty_kable(children_table, "Has Children")
print_pretty_kable(online_table, "Online Booking")
