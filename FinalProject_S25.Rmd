---
title: 'MATH 324 Final Project'
author: "Amy Cao, Amy Folkestad, Anker Hojgaard and Jaxson Stathis"
output:
  pdf_document: default
  html_notebook: default
---

  
```{r, include = F, warning=F, message=F}
# front-matter
rm(list = ls()) #clear the workspace

library(Stat2Data)
library(tidyverse)
library(mosaic)
library(ggformula)
library(emmeans)
library(knitr)
library(kableExtra)
library(dplyr)
library(car)
library(ggplot2)

# install the missing package- this is what was preventing the knit (Amy F already had this installed)
#tinytex::tlmgr_install("multirow")

knitr::opts_chunk$set(echo = F)

# URL to the raw CSV file on GitHub
# this clean version has a series of dates that with odd formatting and missing year and month values as a result
# the dates were reformatted for the affected rows, months and years replaced the missing values

# Use the raw content URL instead of the repository page URL
file_url <- "https://raw.githubusercontent.com/BotanicalAmy/Stats-Project/main/hotel_booking_clean.csv"
hotel_bookings <- read.csv(file_url, header = TRUE)

```

```{r}
# new column GroupSize by adding Adults and Children
hotel_bookings$GroupSize <- hotel_bookings$Adults + hotel_bookings$Children

# new column StayLength by adding weekend and weeknights
hotel_bookings$StayLength <- hotel_bookings$Weekends + hotel_bookings$Weeknights

# Add HasChildren column
hotel_bookings$HasChildren <- ifelse(hotel_bookings$Children > 0, 1, 0)

# Add HasRequest column
hotel_bookings$HasRequests <- ifelse(hotel_bookings$Requests > 0, 1, 0)

# Add Online column
hotel_bookings$Online <- ifelse(hotel_bookings$Market == "Online", 1, 0)

# Preview the data
# head(hotel_bookings)

```

# 1. Project Description

*Description of the dataset*

The dataset includes 36,285 rows of booking data, spanning the course of four years (2015-2018). Data collected includes the group size (adult and children), the stay length (count of weekend and weeknight stays), guest upgrades (parking, meal plans, room types and count of special requests), booking details (price and reservation method), the date of stay, and status (whether or not the guest cancelled the reservation).

Our team observed there was only one row of data for year 2015 and 2016. We additionally noticed there only 5 data points for meal plan 3. GroupSize, StayLength, HasChildren, HasRequests and Online were created from the existing dataset. GroupSize was an aggregation of count of adults and children, StayLength was an aggregation of Weekend and Weeknigths. HasChildren, HasRequests and Online created binary, true/false (0 and 1) variables from the count of children, requests and instances where the market was online.

The status column (cancelled verses not cancelled), is the response variable of interest in this analysis.

*Goal of study*

Gold Mine Resorts is looking to understand the predictors for guests who cancel their reservations.The industry average for cancellation rates is twenty percent; however Gold Mine Resorts experienced a 32.8% cancellation rate for reservations between 2015 and 2018. Cancelled reservations represent a total of $4.3 million dollars in lost revenue for this time frame.

The goal of this analysis is to understand the best predictors for guest cancellations in order to develop company policy in response to predicted cancellations. 

## 1.1 Research Objectives

**Objective 1:**  

The first objective will explore and define the most important quantitative variable for predicting whether a customer will cancel their reservation.

**Objective 2:**

The second objective will explore and define the most important categorical variable for predicting whether a customer will cancel their reservation.

**Objective 3:**

The final goal of our statistical analysis will combine our understanding of quantitative and categorical variables in order to create a final statistical model to predict the customers who are most likely to cancel their reservations.


## 1.2 Variables

The response variable of interest is status, whether or not a client cancelled their booking. The possible explanatory variables include both categorical and quantitative options. The number of requests from a client was converted to a categorical variable. A new column called HasRequests was created, with 1 indicating the customer had a special request. We made a similar to transformation to the children column, transforming this into a binary column indicating whether or not there were children in the group.


*Table of variable names and types*

| Variable    | Description of Variable            | Variable Type |
|-------------|-------------------------------------|--------------|
| Status      | Cancellation status of booking      | C            |
| Meal        | Type of meal plan selected          | C            |
| Parking     | Parking option selection            | C            |
| RoomType    | Type of room booked                 | C            |
| Market      | Market segment of booking           | C            |
| Month       | Month of booking date               | C            |
| Requests    | Number of special requests made     | C            |
| HasChildren | Indicator for children as guests    | C            |
| HasRequests | Indicator for special requests      | C            |
| Online      | Indicator for an online booking     | C            |
| Adults      | Number of adults in the booking     | Q            |
| Children    | Number of children in the booking   | Q            |
| GroupSize   | Number of people in the group       | Q            |
| StayLength  | Total length of stay (nights)       | Q            |
| Weekends    | Number of weekend nights stayed     | Q            |
| Weeknights  | Number of weeknights stayed         | Q            |
| LeadTime    | Num. of days bw booking & arrival   | Q            |
| AvgPrice    | Avg. room price (week of booking)   | Q            |
| Year        | Year of the reservation             | Q            |


\pagebreak

#  2. Detailed Exploratory Data Analysis (EDA)

### Quantitative EDA

For our quantitative exploration, we focused on the aggregated data columns of group size and stay length, in addition to the average price and lead time variables. We did not address children in the quantitative exploration, because we converted the presence of children into categorical variable of HasChildren.

Looking at the side by side box plot, the lead time has the most value for predicting cancellations.

```{r, echo=FALSE}
# quantitative EDA

# Compare means of each quantitative variable between canceled and not canceled groups
group_comparison <- hotel_bookings %>%
  group_by(Status) %>%
  summarize(
    Mean_LeadTime = mean(LeadTime, na.rm = TRUE),
    Mean_AvgPrice = mean(AvgPrice, na.rm = TRUE),
    Mean_GroupSize = mean(GroupSize, na.rm = TRUE),
    Mean_StayLength = mean(StayLength, na.rm = TRUE)
  )

# Round numeric columns to 3 decimal places
group_comparison_formatted <- group_comparison %>%
  mutate(across(where(is.numeric), ~round(., 3)))

# Create pretty kable table
kable(group_comparison_formatted, caption = "Quantitative Explanatory Variables") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                full_width = FALSE) %>%
  column_spec(1, bold = TRUE) %>%
  row_spec(0, bold = TRUE)


hotel_long <- hotel_bookings %>%
  select(Status, LeadTime, AvgPrice, GroupSize, StayLength) %>%
  pivot_longer(cols = c(LeadTime, AvgPrice, GroupSize, StayLength),
               names_to = "Variable",
               values_to = "Value")

# faceted boxplots for quantitative variables
ggplot(hotel_long, aes(x = Status, y = Value, fill = Status)) +
  geom_boxplot() +
  facet_wrap(~ Variable, scales = "free_y") +
  scale_fill_manual(values = c("Canceled" = "#FF6B6B", "Not_Canceled" = "#4ECDC4")) +
  labs(title = "Comparison of quantitative variables by cancellation status") +
  theme_minimal() 

```

\pagebreak

### Categorical EDA

For our categorical exploration, we investigated room type, meal, market, month, request and if the group had children.

Looking at the side by side bar plots, the requests appeared to be the most useful variable, followed by month and market. After analyzing the Online column created from Market, using the non-transformed Market column with all of the variables was more useful for our statistical model.

```{r fig.width=6, fig.height=4, echo=FALSE}
# categorical EDA
# Create a bar chart with white background and title
gf_bar(~RoomType, fill=~Status, data = hotel_bookings) %>%
  gf_labs(
    title = "Cancellation by Room Type",
    x = "Room Type",
    y = "Count"
  ) %>%
  gf_refine(
    scale_fill_manual(values = c("Canceled" = "#FF6B6B", "Not_Canceled" = "#4ECDC4"))
  ) %>%
  gf_theme(
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
      axis.text.x = element_text(angle = 45, hjust = 1),
      legend.position = "bottom"
    )
  )

```

```{r fig.width=7, fig.height=4, echo=FALSE}

gf_bar(~Meal, fill=~Status, data = hotel_bookings) %>%
  gf_labs(
    title = "Cancellation by Meal Type",
    x = "Meal Type",
    y = "Count"
  ) %>%
  gf_refine(
    scale_fill_manual(values = c("Canceled" = "#FF6B6B", "Not_Canceled" = "#4ECDC4"))
  ) %>%
  gf_theme(
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
      legend.position = "bottom"
    )
  )

gf_bar(~Market, fill=~Status, data = hotel_bookings) %>%
  gf_labs(
    title = "Cancellation by Market Segment",
    x = "Market Segment",
    y = "Count"
  ) %>%
  gf_refine(
    scale_fill_manual(values = c("Canceled" = "#FF6B6B", "Not_Canceled" = "#4ECDC4"))
  ) %>%
  gf_theme(
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
      legend.position = "bottom"
    )
  )

```
```{r fig.width=8, fig.height=6, echo=FALSE}
# abbreviated month names in chronological order
month_order <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", 
                "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")

# Convert Month to factor with levels in chronological order
hotel_bookings$Month <- factor(hotel_bookings$Month, levels = month_order)

# Create the bar chart with chronologically ordered months
gf_bar(~Month, fill=~Status, data = hotel_bookings) %>%
  gf_labs(
    title = "Cancellations by Month",
    x = "Month",
    y = "Count"
  ) %>%
  gf_refine(
    scale_fill_manual(values = c("Canceled" = "#FF6B6B", "Not_Canceled" = "#4ECDC4"))
  ) %>%
  gf_theme(
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
      legend.position = "bottom"
    )
  )

```
```{r fig.width=3, fig.height=4, echo=FALSE}
gf_bar(~HasChildren, fill=~Status, data = hotel_bookings) %>%
  gf_labs(
    title = "Cancel by HasChildren",
    x = "Has Children (0 = No, 1 = Yes)",
    y = "Count"
  ) %>%
  gf_refine(
    scale_fill_manual(values = c("Canceled" = "#FF6B6B", "Not_Canceled" = "#4ECDC4"))
  ) %>%
  gf_theme(
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
      legend.position = "bottom"
    )
  )

gf_bar(~Parking, fill=~Status, data = hotel_bookings) %>%
  gf_labs(
    title = "Cancel by Parking",
    x = "Parking",
    y = "Count"
  ) %>%
  gf_refine(
    scale_fill_manual(values = c("Canceled" = "#FF6B6B", "Not_Canceled" = "#4ECDC4"))
  ) %>%
  gf_theme(
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
      legend.position = "bottom"
    )
  )

gf_bar(~HasRequests, fill=~Status, data = hotel_bookings) %>%
  gf_labs(
    title = "Cancel by HasRequest",
    x = "Had a special request",
    y = "Count"
  ) %>%
  gf_refine(
    scale_fill_manual(values = c("Canceled" = "#FF6B6B", "Not_Canceled" = "#4ECDC4"))
  ) %>%
  gf_theme(
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
      legend.position = "bottom"
    )
)

gf_bar(~Online, fill=~Status, data = hotel_bookings) %>%
  gf_labs(
    title = "Cancel by Online",
    x = "Booking type (1 = Online)",
    y = "Count"
  ) %>%
  gf_refine(
    scale_fill_manual(values = c("Canceled" = "#FF6B6B", "Not_Canceled" = "#4ECDC4"))
  ) %>%
  gf_theme(
    theme_minimal() +
    theme(
      plot.title = element_text(face = "bold", size = 14, hjust = 0.5),
      legend.position = "bottom"
    )
)

```

# 3. Statistical Analysis 

## 3.1 Objective 1

The main values that we used to determine the best quantitative predictor were AIC and residual deviance; most of the models we created to find the best predictor of this nature yielded p-values that were lower than 2e-16. However, the AIC and residual deviance for the generalized linear model predicting Status with LeadTime was significantly lower than the values for AvgPrice, StayLength (the new variable synthesized from the number of weekdays and weeknights of each booking), and GroupSize (the new variable combining Adults and Children), reassuring LeadTime's strength as a predictor. With respect to the conditions of this model using only LeadTime, there is some concern about the equal variance condition; the values seem to be exhibiting some flaring near the right edge of the graph. We tried a square-root transformation on this model, but there was little to no improvement, so this was left out of the final model. 

Due to slight flaring of the logit plot, we attempted a variety of transformations (square root, logarithmic, inverse), but this had a negligible impact on the conditions and would make the model difficult to use and understand.

\pagebreak

# Quantitative Model

**Logit function for Status using LeadTime:**
$$\widehat{log(\frac{\pi}{1-\pi})} = 1.8046260 - 0.0117484(LeadTime)$$

$$odds(Status) = e^{1.8046260 - 0.0117484(LeadTime)} $$

**Probability function for Status using LeadTime:**

$$p(Status) = \widehat \pi = \frac{e^{1.8046260 - 0.0117484(LeadTime)}}{1-e^{1.8046260 - 0.0117484(LeadTime)}}$$

$$odds \space ratio = e^{\widehat \beta_1} = e^{-0.0117484} = 0.988324$$ 

For every 1 day increase of LeadTime, the predicted odds of not cancelling the hotel booking decreases by a factor of 0.988. To further Gold Mine Resorts understanding of these statistics, Visuals of the probabilities and odds of cancellation are included below.

$$H_0: \beta_1 = 0, H_a: \beta_1 \neq 0$$
With a p-value < 2e^-16, we have strong evidence to reject the null hypothesis in favor of the alternative. LeadTime is useful for predicting hotel cancellations.


```{r, echo=FALSE}

# quantitative predictors
price_model <- glm(factor(Status) ~ AvgPrice, family = binomial(link = "logit"), data = hotel_bookings)
#summary(price_model)

leadtime_model <- glm(factor(Status) ~ LeadTime, family = binomial(link = "logit"), data = hotel_bookings)
#summary(leadtime_model)

staylength_model <- glm(factor(Status) ~ StayLength, family = binomial(link = "logit"), data = hotel_bookings)
#summary(staylength_model)

groupsize_model <- glm(factor(Status) ~ GroupSize, family = binomial(link = "logit"), data = hotel_bookings)
#summary(groupsize_model)

#ASSESS
#converts status to binary where Canceled = 1 and Not_Canceled = 0, checking for linearity
hotel_bookings$Status_binary <- ifelse(hotel_bookings$Status == "Canceled", 1, 0)
emplogitplot1(Status_binary ~ LeadTime, data = hotel_bookings, ngroups = "all")
plot(leadtime_model, which = 1)

#USE
# summary(leadtime_model)

```

```{r fig.width=8, fig.height=7, echo=FALSE}

# Parameters from your logistic regression model
intercept <- 1.8046260
lead_time_coef <- -0.0117484

# Function to calculate probability of cancellation
cancellation_probability <- function(lead_time) {
  logit <- intercept + (lead_time_coef * lead_time)
  probability <- 1 / (1 + exp(-logit))
  return(probability)
}

# Function to calculate odds of cancellation
cancellation_odds <- function(lead_time) {
  prob <- cancellation_probability(lead_time)
  odds <- prob / (1 - prob)
  return(odds)
}

# Create a sequence of lead times from 0 to 365 days
lead_times <- seq(0, 365, by = 1)

# Calculate probabilities and odds for each lead time
probabilities <- sapply(lead_times, cancellation_probability)
odds <- sapply(lead_times, cancellation_odds)

# Create a data frame for plotting
plot_data <- data.frame(
  LeadTime = lead_times,
  Probability = probabilities,
  Odds = odds
)

# Create visualization
# Set up a 2x1 plotting layout
par(mfrow = c(2, 1), mar = c(4, 4, 2, 2))

# Plot 1: Probability vs Lead Time
plot(plot_data$LeadTime, plot_data$Probability, 
     type = "l", col = "royalblue", lwd = 2,
     xlab = "Lead Time (days)", ylab = "Probability of Cancellation",
     main = "Probability of Cancellation vs Lead Time", 
     ylim = c(0, 1))
grid()

# Add reference points
reference_points <- c(0, 30, 60, 90, 180, 365)
reference_probs <- sapply(reference_points, cancellation_probability)
points(reference_points, reference_probs, pch = 19, col = "#FF6B6B")

# Add labels for probability reference points
text(reference_points, reference_probs, 
     labels = paste0(round(reference_probs*100, 1), "%"), 
     pos = 3, col = "gray11")

# Plot 2: Odds vs Lead Time
plot(plot_data$LeadTime, plot_data$Odds, 
     type = "l", col = "midnightblue", lwd = 2,
     xlab = "Lead Time (days)", ylab = "Odds of Cancellation",
     main = "Odds of Cancellation vs Lead Time",
     ylim = c(0, 6))
grid()

# Add reference points for odds
reference_odds <- sapply(reference_points, cancellation_odds)
points(reference_points, reference_odds, pch = 19, col = "#FF6B6B")

# Add labels for odds reference points
text(reference_points, reference_odds, 
     labels = paste0(round(reference_odds, 2)), 
     pos = 3, col = "gray11")

# Reset plotting parameters
par(mfrow = c(1, 1))

# Additional information: Compare probability and odds changes
# reference_table <- data.frame(
#   LeadTime = reference_points,
#   Probability = round(reference_probs, 4),
#   ProbabilityPercentage = paste0(round(reference_probs*100, 1), "%"),
#   Odds = round(reference_odds, 4)
# )

# Print reference table
# print(reference_table)

# Calculate and display odds ratios for different intervals
# base_odds <- cancellation_odds(0)
# odds_ratios <- sapply(reference_points[-1], function(lt) {
#   cancellation_odds(lt) / base_odds
# })
# 
# cat("\nPercentage change in odds from Lead Time = 0:\n")
# for (i in 1:length(odds_ratios)) {
#   pct_change <- (odds_ratios[i] - 1) * 100
#   cat(sprintf("Lead Time = %d days: %.1f%% change in odds\n", 
#               reference_points[i+1], pct_change))
# }

# Calculate and display odds ratio for one-day change
# one_day_odds_ratio <- exp(lead_time_coef)
# cat(sprintf("\nOdds ratio for one-day increase in lead time: %.4f\n", one_day_odds_ratio))
# cat(sprintf("This corresponds to a %.2f%% decrease in odds per day\n", 
#             (1 - one_day_odds_ratio) * 100))

```

\pagebreak

## 3.2 Objective 2

Looking at the AIC for the categorical models, HasRequests was shown to be the best single categorical explanatory variable for predicting cancellations. As predicted by our exploratory data analysis, this was closely followed by Month and Market.

For our categorical analysis, we transformed Requests (a nominally quantitative variable) into a categorical variable, HasRequests, that indicates whether or not a given booking made a nonzero number of special requests. As evidenced by the model output for HasRequests, we note that the p-value for the variable's coefficient is virtually zero, meaning that HasRequests has an extremely statistically significant effect on cancellation status. We are 95% confident that the aforementioned coefficient lies between 1.05 and 1.14, meaning we are 95% certain that for bookings with special requests, the logarithmic likelihood of a cancellation will increase by a factor of between 1.05 and 1.14.


**Logit function for Status using HasRequests:**

$$\widehat{log(\frac{\pi}{1-\pi})} = 0.27328 + 1.09756(HasRequests)$$

$$odds(Status) = e^{0.27328 + 1.09756(HasRequests)} $$

**Probability function for Status using HasRequests:**

$$p(Status) = \widehat \pi = \frac{e^{0.27328 + 1.09756(HasRequests)}}{1-e^{0.27328 + 1.09756(HasRequests)}}$$

$$odds \space ratio = e^{\widehat \beta_1} = e^{1.09756} = 2.996845$$ 

HasRequests is a binary categorical variable. When HasRequests = 1 the predicted odds of not cancelling are approximately 3 times higher than when HasRequests = 0.

$$H_0: \beta_1 = 0, H_a: \beta_1 \neq 0$$

With a p-value < 2e^-16, we have strong evidence to reject the null hypothesis in favor of the alternative. HasRequests is useful for predicting hotel cancellations.

```{r, echo=FALSE}

modr <- glm(factor(Status) ~ HasRequests, family = binomial(link = "logit"), data = hotel_bookings)
# summary(modr)

plot(modr, which = 1)

#confidence interval for HasRequests
#confint.default(modr)

mod1 <- glm(factor(Status) ~ RoomType, family = binomial(link = "logit"), data = hotel_bookings)
# summary(mod1)

# plot(mod1, which = 1)

mod2 <- glm(factor(Status) ~ Parking, family = binomial(link = "logit"), data = hotel_bookings)
# summary(mod2)

# plot(mod2, which = 1)

mod3 <- glm(factor(Status) ~ Market, family = binomial(link = "logit"), data = hotel_bookings)
# summary(mod3)

# plot(mod3, which = 1)

mod4 <- glm(factor(Status) ~ Meal, family = binomial(link = "logit"), data = hotel_bookings)
# summary(mod4)

# plot(mod4, which = 1)

# mod5 <- glm(factor(Status) ~ Month, family = binomial(link = "logit"), data = hotel_bookings)
# summary(mod5)

#plot(mod5, which = 1)

```

\pagebreak

## 3.3 Objective 3

When observing the ANOVA table, the HasChildren variable was not statistically significant. We replaced the HasChildren variable with Children and still saw observed a large p value, greater than .2 in both instances. We additionally removed year from the statistical model, since this historical data point is not useful for future predictions.

AIC with the forward step analysis recommended using all the remaining variables, including LeadTime, HasRequests, Market, Month, AvgPrice, Parking, RoomType, StayLength, Meal and GroupSize. The AIC of the model was 30,674. 

The large number of variables made us concerned about the potential of overfitting. We used the output from an ANOVA table to eliminate variables one at a time, starting with GroupSize (the highest p value). The final model we selected used LeadTime, Market, Requests, Month, AvgPrice, and StayLength.

While our AIC increased slightly to  31,109, we reduced the variable count from 10 to 6. The 6 variable model had optimized p values for each explanatory variable. Additionally, our model had good variance and normality, in addition to fitting closely to the expected results (as indicated by the empirical logit plot).

The data was divided into ten groups for cross-validation to test the predicted results compared to the actual and produced the following results:

  - Accuracy: 0.806
  - Sensitivity: 0.894
  - Specificity: 0.626
  - AUC: 0.859

The high sensitivity indicates that the model is very good at identifying reservations that will not be cancelled. The specificity value of .626 means our model is more likely to falsely predict a customer will not cancel when they end up cancelling.


```{r, echo=FALSE}
# included again in the appendix, left here for ease of reference or modification
new_model <- glm(factor(Status) ~ LeadTime + factor(Market) + HasRequests + factor(Month) + AvgPrice + StayLength, family = binomial(link = "logit"), data=hotel_bookings)


anova_table <- Anova(new_model, test = "LR")
# print(anova_table)

# Get the AIC
# AIC(new_model)

```

```{r fig.width=7, fig.height=4.5, echo=FALSE}
#ASSESS

# Create an empirical logit plot for the entire model
plot_model_fit <- function(model, bins = 10) {
  # Get predicted probabilities from the model
  pred_probs <- predict(model, type = "response")
  
  # Get actual responses (as 0/1)
  actual <- as.numeric(model$model[[1]]) - 1
  
  # Create bins based on predicted probabilities
  breaks <- quantile(pred_probs, probs = seq(0, 1, length.out = bins + 1))
  bin_groups <- cut(pred_probs, breaks = breaks, include.lowest = TRUE)
  
  # Calculate empirical logit for each bin
  bin_data <- data.frame(
    bin = bin_groups,
    pred = pred_probs,
    actual = actual
  )
  
  # Calculate average predicted probability and observed proportion for each bin
  bin_summary <- aggregate(cbind(pred, actual) ~ bin, data = bin_data, 
                         FUN = function(x) c(mean(x)))
  
  # Calculate empirical logit
  bin_summary$logit_pred <- log(bin_summary$pred / (1 - bin_summary$pred))
  bin_summary$logit_actual <- log((bin_summary$actual + 0.5/nrow(bin_summary)) / 
                               (1 - bin_summary$actual + 0.5/nrow(bin_summary)))
  
  # Count observations per bin
  bin_counts <- table(bin_groups)
  bin_summary$count <- as.vector(bin_counts)
  
  # Create plot
  plot(bin_summary$logit_pred, bin_summary$logit_actual,
       xlab = "Predicted logit", ylab = "Observed logit",
       main = "Empirical Logit Plot for Model Fit",
       pch = 19, cex = sqrt(bin_summary$count / max(bin_summary$count)) * 2)
  
  # Add reference line (y = x)
  abline(0, 1, col = "red", lty = 2)
  
  # Add regression line
  abline(lm(logit_actual ~ logit_pred, data = bin_summary, 
          weights = count), col = "blue")
  
  # Add legend
  legend("topleft", legend = c("Perfect fit", "Actual fit"), 
         col = c("red", "blue"), lty = c(2, 1))
  
  return(bin_summary)
}

# Create the empirical logit plot for the model
model_fit <- plot_model_fit(new_model, bins = 10)

# Print the bin summary data
#print(model_fit)

# Other diagnostic plots for the model
plot(new_model, which = c(1, 2))  # Residuals vs Fitted and Normal Q-Q plot

```


```{r, echo=FALSE}
#cross validation, note- this validation not included in the description (text still notes my original k fold analysis)
# Set seed for reproducibility
set.seed(123)

# Create a random split (80% training, 20% test)
train_indices <- sample(1:nrow(hotel_bookings), size = 0.8 * nrow(hotel_bookings))
train_data <- hotel_bookings[train_indices, ]
test_data <- hotel_bookings[-train_indices, ]

# Build the model on training data
train_model <- glm(factor(Status) ~ LeadTime + factor(Market) + HasRequests + 
                  factor(Month) + AvgPrice + StayLength, 
                  family = binomial(link = "logit"), 
                  data = train_data)

# get predictions for both training and test data
train_predictions <- predict(train_model, newdata = train_data, type = "response")
test_predictions <- predict(train_model, newdata = test_data, type = "response")

# Convert actual values to binary for comparison
train_actual <- as.numeric(factor(train_data$Status)) - 1
test_actual <- as.numeric(factor(test_data$Status)) - 1

# Calculate correlation in training data
# train_correlation <- cor(train_predictions, train_actual)
# print(paste("Training correlation:", round(train_correlation, 4)))

# Calculate correlation in test data (this is the CVC)
# test_correlation <- cor(test_predictions, test_actual)
# print(paste("Cross-validation correlation (CVC):", round(test_correlation, 4)))

# Calculate shrinkage
# shrinkage <- train_correlation - test_correlation
# print(paste("Shrinkage:", round(shrinkage, 4)))
# print(paste("Shrinkage percentage:", round(shrinkage/train_correlation * 100, 2), "%"))

```

\pagebreak

**Key Quantitative Predictors:***

$$odds \space ratio_{LeadTime} = e^{-0.0161356} = 0.984$$ 

For each additional day in lead time, the predicted odds of not cancelling decrease by a factor of 0.984, holding all other variables constant.

$$odds \space ratio_{AvgPrice} = e^{-0.0145549} = 0.985$$ 

For each \$1 increase in average price, the predicted odds of not cancelling decrease by a factor of 0.985, holding all other variables constant. 

$$odds \space ratio_{StayTime} = e^{-0.0643062} = 0.938$$ 

For each additional night in the hotel, the predicted odds of not cancelling decrease by a factor of 0.938, holding all other variables constant.

To summarize, the business implication is that longer lead times, higher prices, and longer stays correlate with higher cancellation risk. In addition, LeadTime, AvgPrice, and StayTime have respective p-values of <2e-16, <2e-16, and 7.49e-16, indicating that these variables are useful to predict Status.

**Key Categorical Predictors:**

$$odds \space ratio_{HasRequests} = e^{2.0247462} = 7.57$$ 

Holding all other variables constant, when a guest makes at least one special request the predicted odds of not cancelling are approximately 8 times higher than those without special requests. With a p-value <2e-16, this variable is useful to predict Status.

$$odds \space ratio_{Market(Corporate)} = e^{1.0866028} = 2.96$$ 

Holding all other variables constant, when Gold Mine Resorts has a corporate booking the predicted odds of not cancelling are approximately 3 times higher than an aviation booking (baseline). With a p-value of 3.95e-07, this segment is useful in predicting Status.

$$odds \space ratio_{Market(Offline)} = e^{1.6324226} = 5.12$$ 

Holding all other variables constant, when Gold Mine Resorts has an offline booking the predicted odds of not cancelling are approximately 5 times higher than an aviation booking (baseline). With a p-value of 8.80e-16, this segment is useful in predicting Status.

$$odds \space ratio_{Market(Online)} = e^{-0.2199951} = 0.8$$ 

Holding all other variables constant, when Gold Mine Resorts has an online booking the predicted odds of not cancelling decrease by a factor of 0.8 compared to an aviation booking (baseline). However, with a p-value of 0.27308, this segment is not statistically significant in predicting Status.

$$odds \space ratio_{Month(Feb-Nov)} \approx e^{-2.28} = 0.102$$

\pagebreak

Holding all other variables constant, when there is a booking made between February to November (all $\beta$'s are relatively similar in range) the predicted odds of not cancelling decrease by a factor of 0.102 when compared to bookings made in January (baseline). Each individual month is statistically significant in predicting Status with p-values <2e-16.

$$odds \space ratio_{Month(Dec)} \approx e^{-0.0643} = 0.55$$ 

Holding all other variables constant, when there is a booking made in December the predicted odds of not cancelling decrease by a factor of 0.55 when compared to bookings made in January (baseline). December is a statistically significant segment of Month in predicting Status with a p-value of 0.00674.

$$H_0: \beta_k = 0, H_a: \beta_k \neq 0$$

To summarize, the business implication is that corporate/offline bookings are more reliable than aviation bookings. In addition, the months of February to November have a higher cancellation risk than January. Specifically, the peak cancellation risk occurs in the month of February where the predicted odds of not cancelling decrease by a factor of 0.059 compared to January (holding all other variables constant).

\pagebreak

# 4. Conclusions 

**Objective 1:**  

Our final conclusion is that LeadTime is the best single quantitative predictor of whether or not a given booking will be cancelled, even when considering new variables synthesized from the dataset for the purpose of analysis. 

```{r}

#gets the confidence interval, which does not include 0 therefore valid
# confint.default(leadtime_model)
#gets the CI on the odds ratio scale, for every 1 unit increase in LeadTime, the odds of cancellation
#(vs. non-cancellation) multiply by 0.9880 to 0.9881 w/95% confidence
# exp(confint.default(leadtime_model))

```

**Objective 2:** 

When considering only the categorical variables available to us from the dataset (and those that we synthesized ourselves), we found that HasRequests (i.e. whether a reservation has any special requests) is the most useful variable for predicting cancellation of bookings.


```{r}

#confidence interval for HasRequests
# confint.default(modr)

```


**Objective 3:**

With all of the original and synthesized variables available to us to pick for our final model, we observed above that the most useful model for predicting booking cancellation status includes the predictors of LeadTime, Market, Month, AvgPrice, and StayLength. Gold Mine Resorts should focus on these categories and note that they are the keys to minimizing cancellations in the future. There additional factors, such as year, that have a role in whether or not people cancel, but these are not able to be controlled by Gold Mine Resorts. 

While this model is a good starting point for predicting hotel cancellations, we noticed that there was a significant increase in both the count of reservations and the count of online reservations that led to cancellations from 2017 to 2018. If Gold Mine Resorts has access to further details about the sources for online bookings, this may prove to be a beneficial research study in the future.


```{r  fig.width=6, fig.height=4.5, echo=FALSE}

# side-by-side bar chart of canceled bookings by market type for 2017-2018
# Filter for canceled bookings in 2017 and 2018 only
canceled_bookings <- hotel_bookings[hotel_bookings$Status == "Canceled" & 
                                    (hotel_bookings$Year == 2017 | 
                                     hotel_bookings$Year == 2018), ]

# Create a binary market type variable (Online vs Non-Online)
canceled_bookings$MarketType <- ifelse(canceled_bookings$Market == "Online", 
                                      "Online", "Non-Online")

# Create a contingency table of counts
cancellation_counts <- table(canceled_bookings$Year, canceled_bookings$MarketType)

# Convert to data frame for ggplot
cancellation_df <- as.data.frame(cancellation_counts)
colnames(cancellation_df) <- c("Year", "MarketType", "Count")

# Convert Year to factor for proper ordering
cancellation_df$Year <- as.factor(cancellation_df$Year)

# Create the side-by-side (unstacked) bar chart
ggplot(cancellation_df, aes(x = Year, y = Count, fill = MarketType)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.7) +
  scale_fill_manual(values = c("Online" = "darkblue", "Non-Online" = "azure4")) +
  labs(title = "Canceled Bookings by Market Type (2017-2018)",
       subtitle = "Side-by-side comparison of Online vs Non-Online Markets",
       x = "Year",
       y = "Number of Cancellations",
       fill = "Market Type") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 12, hjust = 0.5),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    legend.position = "bottom",
    legend.title = element_text(size = 11),
    legend.text = element_text(size = 10),
    panel.grid = element_blank()  # Keep the gridlines removed
  ) +
  # Add data labels on top of each bar
  geom_text(aes(label = Count), position = position_dodge(width = 0.7), 
            vjust = -0.5, size = 3.5) +
  # Set y-axis to start at 0
  scale_y_continuous(expand = expansion(mult = c(0, 0.1)))

```

\pagebreak

# 5. Appendix 

Below are tables used in our exploratory data analysis, followed by the statistical output of our models and cross validation.

**Data Tables**

```{r, echo=FALSE}
# function to generate proportion tables
create_prop_table <- function(data, group_var) {
  group_var <- enquo(group_var)
  
  data %>%
    group_by(!!group_var, Status) %>%
    summarise(count = n(), .groups = "drop") %>%
    group_by(!!group_var) %>%
    mutate(proportion = count / sum(count))
}

# using the function with each variable
room_type_table <- create_prop_table(hotel_bookings, RoomType)
meal_table <- create_prop_table(hotel_bookings, Meal)
market_table <- create_prop_table(hotel_bookings, Market)
parking_table <- create_prop_table(hotel_bookings, Parking)
month_table <- create_prop_table(hotel_bookings, Month)
requests_table <- create_prop_table(hotel_bookings, HasRequests)
children_table <- create_prop_table(hotel_bookings, HasChildren)
online_table <- create_prop_table(hotel_bookings, Online)

# using the function to create a nicely formatted kable table with rounded proportions
print_pretty_kable <- function(table_data, title) {
  table_data <- table_data %>%
    mutate(proportion = round(proportion, 3))
  
  kable(table_data, caption = title) %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"),
                  full_width = FALSE) %>%
    column_spec(1, bold = TRUE) %>%
    row_spec(0, bold = TRUE)
}

#printed tables are separated with lines of code to prevent awkward cut offs

# Print each table with nice formatting
print_pretty_kable(room_type_table, "Room Type")
print_pretty_kable(meal_table, "Meal Option")

```
\pagebreak

```{r, echo=FALSE}
# Print each table with nice formatting
print_pretty_kable(market_table, "Market")
print_pretty_kable(parking_table, "Parking")

```
\pagebreak

```{r, echo=FALSE}
# Print each table with nice formatting
print_pretty_kable(month_table, "Month")
print_pretty_kable(requests_table, "Special Requests")

```

\pagebreak

```{r, echo=FALSE}
# Print each table with nice formatting
print_pretty_kable(children_table, "Has Children")
print_pretty_kable(online_table, "Online Booking")

```
**Quantitative Variable Models**

```{r, include=TRUE}
# quantitative code
price_model <- glm(factor(Status) ~ AvgPrice, family = binomial(link = "logit"), data = hotel_bookings)
summary(price_model)

leadtime_model <- glm(factor(Status) ~ LeadTime, family = binomial(link = "logit"), data = hotel_bookings)
summary(leadtime_model)

staylength_model <- glm(factor(Status) ~ StayLength, family = binomial(link = "logit"), data = hotel_bookings)
summary(staylength_model)

groupsize_model <- glm(factor(Status) ~ GroupSize, family = binomial(link = "logit"), data = hotel_bookings)
summary(groupsize_model)

```
\pagebreak

**Categorical Variable Models**

```{r, include=TRUE}
# categorical code
modr <- glm(factor(Status) ~ Requests, family = binomial(link = "logit"), data = hotel_bookings)
summary(modr)


mod1 <- glm(factor(Status) ~ RoomType, family = binomial(link = "logit"), data = hotel_bookings)
summary(mod1)


mod2 <- glm(factor(Status) ~ Parking, family = binomial(link = "logit"), data = hotel_bookings)
summary(mod2)


mod3 <- glm(factor(Status) ~ Market, family = binomial(link = "logit"), data = hotel_bookings)
summary(mod3)

mod4 <- glm(factor(Status) ~ Meal, family = binomial(link = "logit"), data = hotel_bookings)
summary(mod4)


mod5 <- glm(factor(Status) ~ Month, family = binomial(link = "logit"), data = hotel_bookings)
summary(mod5)

```

**Combined Variable and Final Models**

```{r, include=TRUE}

#full model code
full_model <- glm(factor(Status) ~ factor(Meal) + factor(Parking) + factor(RoomType) + LeadTime + factor(Market) + AvgPrice + HasRequests + factor(Month) + StayLength + GroupSize, family = binomial(link = "logit"), data=hotel_bookings)


none <- glm(factor(Status) ~ 1 , family = binomial(link = "logit"), data=hotel_bookings)
step(none,scope=list(upper= full_model), direction = "forward")

anova_table <- Anova(full_model, test = "LR")
print(anova_table)

#final model code
new_model <- glm(factor(Status) ~ LeadTime + factor(Market) + HasRequests + factor(Month) + AvgPrice + StayLength, family = binomial(link = "logit"), data=hotel_bookings)


anova_table <- Anova(new_model, test = "LR")
print(anova_table)

# Get the AIC
AIC(new_model)

```

**Cross Validation**

```{r, echo=FALSE}
#Cross validation
# Set seed for reproducibility
set.seed(123)

# Define number of folds
k <- 10

# Create folds
folds <- sample(1:k, nrow(hotel_bookings), replace = TRUE)
 
# Initialize performance metrics
cv_metrics <- data.frame(
   fold = 1:k,
   accuracy = numeric(k),
   sensitivity = numeric(k),
   specificity = numeric(k),
   auc = numeric(k)
 )
 
# Perform k-fold cross-validation
 for (i in 1:k) {
   # Split data into training and test sets
   train_data <- hotel_bookings[folds != i, ]
   test_data <- hotel_bookings[folds == i, ]
   
# Fit model on training data
  cv_model <- glm(factor(Status) ~ LeadTime + factor(Market) + HasRequests + 
                  factor(Month) + AvgPrice + StayLength, 
                  family = binomial(link = "logit"), 
                  data = train_data)
   
# Make predictions on test data
   predictions <- predict(cv_model, newdata = test_data, type = "response")
   predicted_class <- ifelse(predictions > 0.5, 1, 0)
   actual_class <- as.numeric(factor(test_data$Status)) - 1
  
   # Create confusion matrix
   conf_matrix <- table(Predicted = predicted_class, Actual = actual_class)
   
   # Calculate performance metrics
   if (dim(conf_matrix)[1] == 2 && dim(conf_matrix)[2] == 2) {
     # When both classes are present in the fold
     accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
     sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[, 2])
     specificity <- conf_matrix[1, 1] / sum(conf_matrix[, 1])
     
     # Calculate AUC
     library(pROC)
     roc_obj <- roc(actual_class, predictions)
    auc_value <- auc(roc_obj)
   } else {
     # Handle edge case when a fold might be missing a class
     accuracy <- sum(predicted_class == actual_class) / length(actual_class)
     sensitivity <- NA
     specificity <- NA
     auc_value <- NA
   }
   
   # Store metrics for this fold
   cv_metrics$accuracy[i] <- accuracy
   cv_metrics$sensitivity[i] <- sensitivity
   cv_metrics$specificity[i] <- specificity
   cv_metrics$auc[i] <- auc_value
 }
 
# Calculate average performance across folds
 cv_summary <- colMeans(cv_metrics[, -1], na.rm = TRUE)
 cv_sd <- apply(cv_metrics[, -1], 2, sd, na.rm = TRUE)
 
# Print results
print("Cross-validation results:")
print(cv_metrics)
print("Average performance:")
print(cv_summary)
print("Standard deviation of performance:")

#data summary of folds
print(cv_sd)

```